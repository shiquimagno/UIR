"""
Simulador de Spaced Repetition con UIR/UIC
Basado en el paper de Shiqui sobre Unidades Internacionales de RetenciÃ³n y ComprensiÃ³n
"""

import streamlit as st
import numpy as np
import pandas as pd
import json
import os
from datetime import datetime, timedelta
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass, asdict, field
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import plotly.express as px
import plotly.graph_objects as go
import networkx as nx
from pyvis.network import Network
import matplotlib.pyplot as plt
from scipy.optimize import minimize
import time

# Importar mÃ³dulo de autenticaciÃ³n
import auth

# ============================================================================
# DATA STRUCTURES
# ============================================================================

@dataclass
class ReviewHistory:
    """Registro de un repaso individual"""
    timestamp: str
    grade: int  # 0=Again, 1=Hard, 2=Good, 3=Easy
    response_time: float  # segundos
    reading_time: float  # segundos hasta mostrar respuesta
    P_recall: float  # probabilidad de recordar estimada
    interval_days: int  # intervalo hasta este repaso
    
@dataclass
class Card:
    """Tarjeta de estudio con metadatos UIR/UIC"""
    id: str
    question: str
    answer: str
    tags: List[str] = field(default_factory=list)
    created_at: str = field(default_factory=lambda: datetime.now().isoformat())
    
    # Estado de repaso
    last_review: Optional[str] = None
    next_review: Optional[str] = None
    review_count: int = 0
    
    # ParÃ¡metros UIR/UIC
    UIC_local: float = 0.0
    UIR_base: float = 7.0  # dÃ­as (valor inicial razonable)
    UIR_effective: float = 7.0
    
    # ParÃ¡metros Anki clÃ¡sico
    easiness_factor: float = 2.5
    interval_days: int = 1
    repetition_count: int = 0
    
    # Historial
    history: List[ReviewHistory] = field(default_factory=list)
    
    # Estado y notas (Phase 3)
    status: str = "active"  # active, suspended, archived
    notes: str = ""  # Notas personales
    mnemonics: str = ""  # TÃ©cnicas mnemotÃ©cnicas

@dataclass
class User:
    """Usuario del sistema"""
    username: str
    password_hash: str  # Hash de la contraseÃ±a (no guardar en texto plano)
    created_at: str = field(default_factory=lambda: datetime.now().isoformat())
    last_updated: str = field(default_factory=lambda: datetime.now().isoformat())

@dataclass
class AppState:
    """Estado global de la aplicaciÃ³n"""
    cards: List[Card] = field(default_factory=list)
    params: Dict[str, float] = field(default_factory=lambda: {
        'alpha': 0.2,
        'gamma': 0.15,
        'delta': 0.02,
        'eta': 0.05
    })
    tfidf_matrix: Optional[np.ndarray] = None
    similarity_matrix: Optional[np.ndarray] = None
    last_updated: str = field(default_factory=lambda: datetime.now().isoformat())

# ============================================================================
# PERSISTENCE
# ============================================================================

DATA_DIR = "data"
STATE_FILE = os.path.join(DATA_DIR, "state.json")

def ensure_data_dir():
    """Crear directorio de datos si no existe"""
    os.makedirs(DATA_DIR, exist_ok=True)
    os.makedirs(os.path.join(DATA_DIR, "backups"), exist_ok=True)
    os.makedirs(os.path.join(DATA_DIR, "auto_backups"), exist_ok=True)

def auto_backup():
    """
    Crear backup automÃ¡tico diario
    Se ejecuta al inicio de la app
    Mantiene Ãºltimos 7 dÃ­as de backups
    """
    try:
        if not os.path.exists(STATE_FILE):
            return
        
        # Asegurar que el directorio existe
        ensure_data_dir()
        
        auto_backup_dir = os.path.join(DATA_DIR, "auto_backups")
        date_str = datetime.now().strftime("%Y%m%d")
        backup_file = os.path.join(auto_backup_dir, f"state_{date_str}.json")
        
        # Solo crear backup si no existe uno de hoy
        if not os.path.exists(backup_file):
            import shutil
            shutil.copy(STATE_FILE, backup_file)
            
            # Limpiar backups antiguos (mantener Ãºltimos 7 dÃ­as)
            all_backups = sorted([
                f for f in os.listdir(auto_backup_dir) 
                if f.startswith("state_") and f.endswith(".json")
            ])
            
            if len(all_backups) > 7:
                for old_backup in all_backups[:-7]:
                    try:
                        os.remove(os.path.join(auto_backup_dir, old_backup))
                    except:
                        pass  # Ignorar errores al eliminar backups antiguos
    except Exception as e:
        # No fallar la app si el backup falla
        # Solo registrar el error silenciosamente
        pass


def save_state(state: AppState):
    """Guardar estado en JSON"""
    ensure_data_dir()
    
    # Backup anterior
    if os.path.exists(STATE_FILE):
        backup_file = os.path.join(DATA_DIR, "backups", 
                                   f"state_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
        os.rename(STATE_FILE, backup_file)
    
    # Convertir a dict serializable
    state_dict = {
        'cards': [asdict(card) for card in state.cards],
        'params': state.params,
        'last_updated': datetime.now().isoformat()
    }
    
    with open(STATE_FILE, 'w', encoding='utf-8') as f:
        json.dump(state_dict, f, indent=2, ensure_ascii=False)

def load_state() -> AppState:
    """Cargar estado desde JSON"""
    if not os.path.exists(STATE_FILE):
        return AppState()
    
    try:
        with open(STATE_FILE, 'r', encoding='utf-8') as f:
            state_dict = json.load(f)
        
        # Reconstruir objetos
        cards = [Card(**card_data) for card_data in state_dict.get('cards', [])]
        # Reconstruir history como objetos ReviewHistory
        for card in cards:
            card.history = [ReviewHistory(**h) if isinstance(h, dict) else h 
                           for h in card.history]
        
        return AppState(
            cards=cards,
            params=state_dict.get('params', AppState().params),
            last_updated=state_dict.get('last_updated', datetime.now().isoformat())
        )
    except Exception as e:
        st.error(f"Error cargando estado: {e}")
        return AppState()

# ============================================================================
# CORE ALGORITHMS - UIR/UIC
# ============================================================================

def compute_uir_from_p(t: float, P: float, epsilon: float = 0.01) -> float:
    """
    Calcula UIR = -t / ln(P) con suavizado para evitar log(0)
    
    Args:
        t: tiempo transcurrido (dÃ­as)
        P: probabilidad de recordar [0,1]
        epsilon: suavizado para P cercano a 0 o 1
    
    Returns:
        UIR en dÃ­as
    """
    # Suavizado Laplace
    P_smooth = np.clip(P, epsilon, 1 - epsilon)
    
    if t <= 0:
        return 7.0  # valor por defecto
    
    UIR = -t / np.log(P_smooth)
    return max(1.0, UIR)  # mÃ­nimo 1 dÃ­a

def get_spanish_stop_words() -> List[str]:
    """
    Retorna lista completa de stop words en espaÃ±ol
    Incluye palabras interrogativas, conectores y palabras comunes sin valor semÃ¡ntico
    """
    return [
        # Palabras interrogativas (lo mÃ¡s importante para filtrar)
        'quÃ©', 'que', 'cuÃ¡l', 'cual', 'cuÃ¡les', 'cuales', 'cÃ³mo', 'como',
        'dÃ³nde', 'donde', 'cuÃ¡ndo', 'cuando', 'cuÃ¡nto', 'cuanto', 'cuÃ¡ntos', 'cuantos',
        'cuÃ¡nta', 'cuanta', 'cuÃ¡ntas', 'cuantas', 'quiÃ©n', 'quien', 'quiÃ©nes', 'quienes',
        'por', 'quÃ©', 'para', 'porquÃ©', 'porque',
        
        # Verbos copulativos y auxiliares comunes en preguntas
        'es', 'son', 'era', 'eran', 'fue', 'fueron', 'sea', 'sean',
        'estÃ¡', 'esta', 'estÃ¡n', 'estan', 'estaba', 'estaban',
        'ser', 'estar', 'hay', 'haber', 'sido', 'estado',
        'tiene', 'tienen', 'tenÃ­a', 'tenia', 'tenÃ­an', 'tenian',
        'hace', 'hacen', 'hizo', 'hicieron',
        
        # Verbos comunes en preguntas
        'significa', 'significan', 'significa', 'sirve', 'sirven',
        'funciona', 'funcionan', 'define', 'definen',
        'representa', 'representan', 'implica', 'implican',
        
        # ArtÃ­culos
        'el', 'la', 'los', 'las', 'un', 'una', 'unos', 'unas',
        
        # Preposiciones
        'a', 'ante', 'bajo', 'con', 'contra', 'de', 'desde', 'en',
        'entre', 'hacia', 'hasta', 'mediante', 'para', 'por', 'segÃºn',
        'sin', 'sobre', 'tras', 'durante', 'versus', 'vÃ­a',
        
        # Conjunciones
        'y', 'e', 'o', 'u', 'pero', 'sino', 'aunque', 'si', 'ni',
        'que', 'porque', 'pues', 'ya', 'sea', 'bien', 'asÃ­',
        
        # Pronombres
        'yo', 'tÃº', 'tu', 'Ã©l', 'el', 'ella', 'nosotros', 'vosotros', 'ellos', 'ellas',
        'me', 'te', 'se', 'nos', 'os', 'le', 'les', 'lo', 'la', 'los', 'las',
        'mi', 'mis', 'su', 'sus', 'nuestro', 'nuestra', 'vuestro', 'vuestra',
        'este', 'esta', 'estos', 'estas', 'ese', 'esa', 'esos', 'esas',
        'aquel', 'aquella', 'aquellos', 'aquellas', 'esto', 'eso', 'aquello',
        
        # Adverbios comunes
        'muy', 'mÃ¡s', 'mas', 'menos', 'poco', 'mucho', 'bastante', 'demasiado',
        'tan', 'tanto', 'tambiÃ©n', 'tampoco', 'sÃ­', 'si', 'no', 'nunca', 'siempre',
        'jamÃ¡s', 'jamas', 'apenas', 'solo', 'sÃ³lo', 'solamente',
        'aquÃ­', 'aqui', 'ahÃ­', 'ahi', 'allÃ­', 'alli', 'acÃ¡', 'aca', 'allÃ¡', 'alla',
        'hoy', 'ayer', 'maÃ±ana', 'ahora', 'luego', 'despuÃ©s', 'despues', 'antes',
        
        # Otros
        'otro', 'otra', 'otros', 'otras', 'mismo', 'misma', 'mismos', 'mismas',
        'tal', 'tales', 'todo', 'toda', 'todos', 'todas', 'algÃºn', 'algun',
        'alguno', 'alguna', 'algunos', 'algunas', 'ningÃºn', 'ningun', 'ninguno', 'ninguna',
        'cada', 'varios', 'varias', 'ambos', 'ambas', 'cualquier', 'cualesquiera',
        
        # Palabras de relleno
        'cosa', 'cosas', 'algo', 'nada', 'alguien', 'nadie', 'vez', 'veces'
    ]


@st.cache_data
def compute_tfidf(cards_data: Tuple[Tuple[str, str, str], ...]) -> Tuple[Optional[np.ndarray], Optional[object]]:
    """
    Construye matriz TF-IDF de preguntas + respuestas
    Filtra stop words en espaÃ±ol (palabras interrogativas, conectores, etc.)
    para enfocarse en palabras nÃºcleo con valor semÃ¡ntico
    
    Args:
        cards_data: Tupla de tuplas (id, question, answer) para hashing
    
    Returns:
        (matriz TF-IDF, vectorizer) o (None, None) si no hay suficientes tarjetas
    """
    if len(cards_data) < 2:
        return None, None
    
    # Reconstruir documentos desde cards_data
    documents = [f"{q} {a}" for _, q, a in cards_data]
    
    try:
        # Obtener stop words personalizadas
        custom_stop_words = get_spanish_stop_words()
        
        vectorizer = TfidfVectorizer(
            max_features=100,
            stop_words=custom_stop_words,  # Filtrar palabras sin valor semÃ¡ntico
            ngram_range=(1, 2),  # Unigramas y bigramas
            lowercase=True,  # Normalizar a minÃºsculas
            strip_accents='unicode',  # Normalizar acentos para mejor matching
            token_pattern=r'(?u)\b\w\w+\b'  # Palabras de 2+ caracteres
        )
        tfidf_matrix = vectorizer.fit_transform(documents)
        return tfidf_matrix.toarray(), vectorizer
    except Exception as e:
        st.warning(f"Error calculando TF-IDF: {e}")
        return None, None

def compute_tfidf_from_cards(cards: List[Card]) -> Tuple[Optional[np.ndarray], Optional[object]]:
    """
    Wrapper para compute_tfidf que convierte List[Card] a formato cacheable
    """
    # Convertir cards a tupla de tuplas para que sea hashable
    cards_data = tuple((c.id, c.question, c.answer) for c in cards)
    return compute_tfidf(cards_data)



def compute_similarity_matrix(tfidf_matrix: np.ndarray) -> np.ndarray:
    """
    Calcula matriz de similitud coseno rectificada [0,1]
    Diagonal = 0 (no auto-similitud)
    """
    W = cosine_similarity(tfidf_matrix)
    W = np.clip(W, 0, 1)  # rectificar a [0,1]
    np.fill_diagonal(W, 0)  # diagonal a 0
    return W

def compute_UIC_global(W: np.ndarray) -> float:
    """
    UIC global = sum(w_ij) / (n*(n-1))
    """
    n = W.shape[0]
    if n < 2:
        return 0.0
    
    total_similarity = np.sum(W)
    return total_similarity / (n * (n - 1))

def compute_UIC_local(W: np.ndarray, card_idx: int, k: int = 5) -> float:
    """
    UIC local = promedio de similitud entre k vecinos mÃ¡s cercanos
    
    Args:
        W: matriz de similitud
        card_idx: Ã­ndice de la tarjeta
        k: nÃºmero de vecinos a considerar
    """
    n = W.shape[0]
    if n < 2:
        return 0.0
    
    # Obtener similitudes con otras tarjetas
    similarities = W[card_idx, :]
    
    # Top k vecinos (excluyendo la propia tarjeta)
    k_actual = min(k, n - 1)
    if k_actual == 0:
        return 0.0
    
    top_k_indices = np.argsort(similarities)[-k_actual:]
    
    # UIC local = promedio de similitud entre vecinos
    if len(top_k_indices) < 2:
        return np.mean(similarities[top_k_indices]) if len(top_k_indices) > 0 else 0.0
    
    # Similitud promedio entre pares de vecinos
    neighbor_similarities = []
    for i in range(len(top_k_indices)):
        for j in range(i + 1, len(top_k_indices)):
            neighbor_similarities.append(W[top_k_indices[i], top_k_indices[j]])
    
    return np.mean(neighbor_similarities) if neighbor_similarities else 0.0

def update_on_review(card: Card, grade: int, response_time: float, 
                    reading_time: float, params: Dict[str, float]):
    """
    Actualiza UIC_local, UIR_base, UIR_eff segÃºn fÃ³rmulas del paper
    
    Args:
        card: tarjeta a actualizar
        grade: 0=Again, 1=Hard, 2=Good, 3=Easy
        response_time: tiempo de respuesta en segundos
        reading_time: tiempo de lectura en segundos
        params: parÃ¡metros del modelo (alpha, gamma, delta, eta)
    """
    # Mapear grade a probabilidad de recordar
    grade_to_p = {0: 0.0, 1: 0.4, 2: 0.7, 3: 0.95}
    p_t = grade_to_p.get(grade, 0.5)
    
    # Actualizar UIC (ecuaciÃ³n discreta)
    gamma = params['gamma']
    delta = params['delta']
    
    UIC_old = card.UIC_local
    UIC_increment = gamma * p_t * (1 - UIC_old)
    UIC_decrement = delta * (1 - p_t) * UIC_old
    card.UIC_local = np.clip(UIC_old + UIC_increment - UIC_decrement, 0, 1)
    
    # Actualizar UIR_base
    eta = params['eta']
    card.UIR_base = card.UIR_base + eta * p_t * card.UIC_local
    card.UIR_base = max(1.0, card.UIR_base)
    
    # Calcular UIR_effective
    alpha = params['alpha']
    card.UIR_effective = card.UIR_base * (1 + alpha * card.UIC_local)
    
    # Registrar en historial
    interval_days = 0
    if card.last_review:
        last_dt = datetime.fromisoformat(card.last_review)
        interval_days = (datetime.now() - last_dt).days
    
    review = ReviewHistory(
        timestamp=datetime.now().isoformat(),
        grade=grade,
        response_time=response_time,
        reading_time=reading_time,
        P_recall=p_t,
        interval_days=interval_days
    )
    card.history.append(review)
    
    # Actualizar metadatos
    card.last_review = datetime.now().isoformat()
    card.review_count += 1

# ============================================================================
# SCHEDULING ALGORITHMS
# ============================================================================

def compute_success_rate(card: Card) -> float:
    """
    Calcula tasa de Ã©xito reciente (Ãºltimos 5 repasos)
    
    Returns:
        Float entre 0 y 1 (0.5 si no hay historial)
    """
    if not card.history:
        return 0.5  # Neutral para tarjetas nuevas
    
    recent = card.history[-5:]  # Ãšltimos 5 repasos
    successes = 0
    for r in recent:
        # Manejar tanto dict como ReviewHistory object
        grade = r.grade if hasattr(r, 'grade') else r.get('grade', 0)
        if grade >= 2:  # Good o Easy
            successes += 1
    
    return successes / len(recent)

def compute_anki_interval_pure(n: int, EF: float, I_prev: int, grade: int) -> Tuple[int, float, int]:
    """
    Calcula intervalo Anki sin modificar la tarjeta (funciÃ³n pura)
    
    Returns:
        (nuevo_intervalo, nuevo_EF, nuevo_n)
    """
    if grade == 0:  # Again
        return 1, max(1.3, EF - 0.2), 0
    elif grade == 1:  # Hard
        return max(1, round(I_prev * 1.2)), max(1.3, EF - 0.15), n + 1
    elif grade == 2:  # Good
        if n == 0:
            return 1, EF, n + 1
        elif n == 1:
            return 6, EF, n + 1
        else:
            return round(I_prev * EF), EF, n + 1
    else:  # Easy (grade == 3)
        if n == 0:
            return 4, EF + 0.1, n + 1
        else:
            return round(I_prev * EF * 1.3), EF + 0.1, n + 1

def anki_classic_schedule(card: Card, grade: int) -> int:
    """
    Algoritmo Anki clÃ¡sico (SM-2 simplificado)
    Modifica la tarjeta in-place
    
    Returns:
        PrÃ³ximo intervalo en dÃ­as
    """
    I_new, EF_new, n_new = compute_anki_interval_pure(
        card.repetition_count,
        card.easiness_factor,
        card.interval_days,
        grade
    )
    
    # Actualizar tarjeta
    card.interval_days = I_new
    card.easiness_factor = EF_new
    card.repetition_count = n_new
    
    return I_new

def compute_uir_modulation_factor(card: Card, grade: int, params: Dict[str, float]) -> float:
    """
    Calcula factor de modulaciÃ³n basado en UIR/UIC
    
    Factor combina:
    - Progreso de retenciÃ³n (UIR_eff / UIR_inicial)
    - Refuerzo semÃ¡ntico (UIC_local)
    - Historial de Ã©xito
    - Dificultad percibida (grade)
    
    Returns:
        Factor entre 0.5 y 2.5
    """
    UIR_INICIAL = 7.0  # UIR de referencia inicial
    
    # 1. Ratio UIR (progreso de retenciÃ³n)
    UIR_ratio = card.UIR_effective / UIR_INICIAL
    
    # 2. Factor UIC (refuerzo semÃ¡ntico)
    # Tarjetas conectadas â†’ intervalos mÃ¡s largos
    UIC_factor = 1 + params['alpha'] * card.UIC_local
    
    # 3. Factor de Ã©xito (historial reciente)
    success_rate = compute_success_rate(card)
    success_factor = 0.7 + 0.6 * success_rate  # Rango [0.7, 1.3]
    
    # 4. Factor de dificultad percibida
    grade_factors = {
        0: 0.5,   # Again: acortar mucho
        1: 0.8,   # Hard: acortar un poco
        2: 1.0,   # Good: neutral
        3: 1.3    # Easy: alargar
    }
    grade_factor = grade_factors.get(grade, 1.0)
    
    # Combinar todos los factores
    total_factor = UIR_ratio * UIC_factor * success_factor * grade_factor
    
    # Limitar rango para evitar extremos
    return np.clip(total_factor, 0.5, 2.5)

def anki_uir_adapted_schedule(card: Card, grade: int, params: Dict[str, float]) -> int:
    """
    Algoritmo hÃ­brido Anki+UIR mejorado
    
    Combina:
    - Intervalo base de Anki (experiencia acumulada)
    - Factor de modulaciÃ³n UIR/UIC (retenciÃ³n individual + contexto semÃ¡ntico)
    
    Returns:
        PrÃ³ximo intervalo en dÃ­as
    """
    # 1. Calcular intervalo Anki (sin modificar card)
    I_anki, _, _ = compute_anki_interval_pure(
        card.repetition_count,
        card.easiness_factor,
        card.interval_days,
        grade
    )
    
    # 2. Calcular factor de modulaciÃ³n UIR
    UIR_factor = compute_uir_modulation_factor(card, grade, params)
    
    # 3. Aplicar modulaciÃ³n
    I_final = round(I_anki * UIR_factor)
    
    return max(1, I_final)

def predict_intervals_for_all_grades(card: Card, params: Dict[str, float]) -> Dict[str, Dict[int, int]]:
    """
    Predice intervalos para todas las opciones de calificaciÃ³n
    Ãštil para mostrar en UI antes de que el usuario elija
    
    Returns:
        {
            'anki_classic': {0: dÃ­as, 1: dÃ­as, 2: dÃ­as, 3: dÃ­as},
            'anki_uir': {0: dÃ­as, 1: dÃ­as, 2: dÃ­as, 3: dÃ­as}
        }
    """
    predictions = {
        'anki_classic': {},
        'anki_uir': {}
    }
    
    for grade in [0, 1, 2, 3]:
        # Anki clÃ¡sico (funciÃ³n pura, no modifica card)
        I_anki, _, _ = compute_anki_interval_pure(
            card.repetition_count,
            card.easiness_factor,
            card.interval_days,
            grade
        )
        predictions['anki_classic'][grade] = I_anki
        
        # Anki+UIR
        UIR_factor = compute_uir_modulation_factor(card, grade, params)
        I_uir = round(I_anki * UIR_factor)
        predictions['anki_uir'][grade] = max(1, I_uir)
    
    return predictions

def compute_next_review_date(card: Card, interval_days: int) -> str:
    """Calcula fecha de prÃ³ximo repaso"""
    next_date = datetime.now() + timedelta(days=interval_days)
    return next_date.isoformat()

def compute_streak(cards: List[Card]) -> int:
    """
    Calcula la racha actual de dÃ­as consecutivos con repasos
    
    Returns:
        NÃºmero de dÃ­as consecutivos con al menos un repaso
    """
    if not cards:
        return 0
    
    # Obtener todas las fechas Ãºnicas de repasos
    review_dates = set()
    for card in cards:
        for review in card.history:
            timestamp = review.timestamp if hasattr(review, 'timestamp') else review.get('timestamp', '')
            if timestamp:
                try:
                    date = datetime.fromisoformat(timestamp).date()
                    review_dates.add(date)
                except:
                    pass
    
    if not review_dates:
        return 0
    
    # Ordenar fechas de mÃ¡s reciente a mÃ¡s antigua
    sorted_dates = sorted(review_dates, reverse=True)
    
    # Calcular racha
    today = datetime.now().date()
    streak = 0
    
    # Verificar si hay repaso hoy o ayer (para no romper racha)
    if sorted_dates[0] not in [today, today - timedelta(days=1)]:
        return 0
    
    # Contar dÃ­as consecutivos
    expected_date = sorted_dates[0]
    for date in sorted_dates:
        if date == expected_date:
            streak += 1
            expected_date = date - timedelta(days=1)
        else:
            break
    
    return streak

# ============================================================================
# STREAMLIT APP INITIALIZATION
# ============================================================================

# Ejecutar backup automÃ¡tico al inicio
auto_backup()

# ============================================================================
# AUTHENTICATION CHECK
# ============================================================================

# Inicializar session state para autenticaciÃ³n
if 'authenticated' not in st.session_state:
    st.session_state.authenticated = False
    st.session_state.username = None

# Inicializar dark mode
if 'dark_mode' not in st.session_state:
    st.session_state.dark_mode = False

# Si no estÃ¡ autenticado, mostrar pÃ¡gina de login
if not st.session_state.authenticated:
    auth.show_auth_page()
    st.stop()

# ============================================================================
# MAIN APP (Solo si estÃ¡ autenticado)
# ============================================================================

# Cargar estado especÃ­fico del usuario
username = st.session_state.username
STATE_FILE = auth.get_user_state_file(username)

# Inicializar session state
if 'state' not in st.session_state:
    st.session_state.state = load_state()

if 'current_page' not in st.session_state:
    st.session_state.current_page = "Dashboard"

if 'review_session' not in st.session_state:
    st.session_state.review_session = {
        'active': False,
        'current_card_idx': 0,
        'cards_to_review': [],
        'show_answer': False,
        'start_time': None,
        'show_time': None
    }

state = st.session_state.state

# ============================================================================
# NAVIGATION
# ============================================================================

st.sidebar.title("ğŸ§  Simulador UIR/UIC")
st.sidebar.markdown("---")

pages = [
    "Dashboard",
    "Crear/Importar Tarjetas",
    "SesiÃ³n de Repaso",
    "ğŸ“Š Analytics",
    "Grafo SemÃ¡ntico",
    "Comparador de Algoritmos",
    "SimulaciÃ³n",
    "CalibraciÃ³n",
    "Export/Import"
]

st.session_state.current_page = st.sidebar.radio("NavegaciÃ³n", pages, 
                                                  index=pages.index(st.session_state.current_page))

st.sidebar.markdown("---")
st.sidebar.markdown(f"**Tarjetas totales:** {len(state.cards)}")
st.sidebar.markdown(f"**UIC global:** {compute_UIC_global(state.similarity_matrix) if state.similarity_matrix is not None else 0:.3f}")

# Mostrar racha
if state.cards:
    streak = compute_streak(state.cards)
    if streak > 0:
        st.sidebar.markdown(f"ğŸ”¥ **Racha:** {streak} dÃ­as")
        if streak >= 7:
            st.sidebar.success("Â¡Semana completa!")
        if streak >= 30:
            st.sidebar.success("ğŸ† Â¡Mes completo!")

# ============================================================================
# PAGE FUNCTIONS
# ============================================================================

def page_dashboard():
    """Dashboard principal con mÃ©tricas y resumen"""
    st.title("ğŸ“Š Dashboard")
    
    # MÃ©tricas principales
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Total Tarjetas", len(state.cards))
    
    with col2:
        uic_global = compute_UIC_global(state.similarity_matrix) if state.similarity_matrix is not None else 0
        st.metric("UIC Global", f"{uic_global:.3f}")
    
    with col3:
        avg_uir = np.mean([c.UIR_effective for c in state.cards]) if state.cards else 0
        st.metric("UIR Promedio", f"{avg_uir:.1f} dÃ­as")
    
    with col4:
        # Tarjetas pendientes hoy
        today = datetime.now()
        pending = sum(1 for c in state.cards 
                     if c.next_review and datetime.fromisoformat(c.next_review) <= today)
        st.metric("Pendientes Hoy", pending)
    
    st.markdown("---")
    
    # BotÃ³n de inicio rÃ¡pido
    if st.button("ğŸš€ Empezar SesiÃ³n de Repaso", type="primary", use_container_width=True):
        st.session_state.current_page = "SesiÃ³n de Repaso"
        st.rerun()
    
    # GrÃ¡ficas mejoradas
    if state.cards:
        # Tabs para organizar visualizaciones
        tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“ˆ Actividad", "ğŸ“Š Distribuciones", "ğŸ”„ RetenciÃ³n", "ğŸ“… Timeline"])
        
        with tab1:
            st.subheader("Actividad de Repasos")
            
            # Recopilar historial de todos los repasos
            all_reviews = []
            for card in state.cards:
                for review in card.history:
                    timestamp = review.timestamp if hasattr(review, 'timestamp') else review.get('timestamp', '')
                    grade = review.grade if hasattr(review, 'grade') else review.get('grade', 0)
                    if timestamp:
                        all_reviews.append({
                            'timestamp': datetime.fromisoformat(timestamp),
                            'grade': grade
                        })
            
            if all_reviews:
                df_reviews = pd.DataFrame(all_reviews)
                df_reviews['date'] = df_reviews['timestamp'].dt.date
                
                # GrÃ¡fica de barras por dÃ­a
                daily_reviews = df_reviews.groupby('date').size().reset_index(name='count')
                fig1 = px.bar(daily_reviews, x='date', y='count', 
                            title="Repasos por DÃ­a",
                            labels={'date': 'Fecha', 'count': 'NÃºmero de Repasos'})
                st.plotly_chart(fig1, use_container_width=True)
                
                # Calendario de calor (heatmap de actividad)
                df_reviews['day_of_week'] = df_reviews['timestamp'].dt.day_name()
                df_reviews['hour'] = df_reviews['timestamp'].dt.hour
                heatmap_data = df_reviews.groupby(['day_of_week', 'hour']).size().reset_index(name='count')
                
                # Ordenar dÃ­as de la semana
                day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
                heatmap_pivot = heatmap_data.pivot(index='day_of_week', columns='hour', values='count').fillna(0)
                heatmap_pivot = heatmap_pivot.reindex(day_order)
                
                fig_heat = px.imshow(heatmap_pivot,
                                    labels=dict(x="Hora del DÃ­a", y="DÃ­a de la Semana", color="Repasos"),
                                    title="PatrÃ³n de Actividad (Heatmap)",
                                    color_continuous_scale="Blues")
                st.plotly_chart(fig_heat, use_container_width=True)
            else:
                st.info("No hay repasos registrados aÃºn.")
        
        with tab2:
            st.subheader("Distribuciones")
            
            col_a, col_b = st.columns(2)
            
            with col_a:
                # DistribuciÃ³n de UIC
                uic_values = [c.UIC_local for c in state.cards]
                fig_uic = px.histogram(x=uic_values, nbins=20,
                                      title="DistribuciÃ³n de UIC Local",
                                      labels={'x': 'UIC Local', 'y': 'Frecuencia'})
                st.plotly_chart(fig_uic, use_container_width=True)
            
            with col_b:
                # DistribuciÃ³n de UIR
                uir_values = [c.UIR_effective for c in state.cards]
                fig_uir = px.histogram(x=uir_values, nbins=20,
                                      title="DistribuciÃ³n de UIR Efectivo",
                                      labels={'x': 'UIR Efectivo (dÃ­as)', 'y': 'Frecuencia'})
                st.plotly_chart(fig_uir, use_container_width=True)
            
            # DistribuciÃ³n de intervalos
            intervals = []
            for c in state.cards:
                if c.next_review:
                    try:
                        next_dt = datetime.fromisoformat(c.next_review)
                        days_until = (next_dt - datetime.now()).days
                        intervals.append(max(0, days_until))
                    except:
                        pass
            
            if intervals:
                fig_int = px.histogram(x=intervals, nbins=30,
                                      title="DistribuciÃ³n de PrÃ³ximos Repasos",
                                      labels={'x': 'DÃ­as hasta prÃ³ximo repaso', 'y': 'Frecuencia'})
                st.plotly_chart(fig_int, use_container_width=True)
        
        with tab3:
            st.subheader("Curva de RetenciÃ³n Promedio")
            
            # Calcular curva P(t) = exp(-t/UIR_eff) promedio
            avg_uir_eff = np.mean([c.UIR_effective for c in state.cards]) if state.cards else 7.0
            
            t_values = np.linspace(0, 90, 100)
            p_values = np.exp(-t_values / avg_uir_eff)
            
            fig_retention = go.Figure()
            fig_retention.add_trace(go.Scatter(x=t_values, y=p_values,
                                              mode='lines',
                                              name=f'P(t) = exp(-t/{avg_uir_eff:.1f})',
                                              line=dict(color='blue', width=3)))
            
            # LÃ­nea de referencia (37% en t=UIR)
            fig_retention.add_hline(y=0.37, line_dash="dash", line_color="red",
                                   annotation_text="37% (1/e)")
            fig_retention.add_vline(x=avg_uir_eff, line_dash="dash", line_color="red",
                                   annotation_text=f"UIR={avg_uir_eff:.1f}d")
            
            fig_retention.update_layout(
                title="Curva de RetenciÃ³n Promedio",
                xaxis_title="Tiempo (dÃ­as)",
                yaxis_title="Probabilidad de Recordar",
                yaxis=dict(range=[0, 1])
            )
            st.plotly_chart(fig_retention, use_container_width=True)
            
            st.caption(f"ğŸ“Š UIR promedio: {avg_uir_eff:.1f} dÃ­as - Probabilidad cae a 37% despuÃ©s de {avg_uir_eff:.1f} dÃ­as")
        
        with tab4:
            st.subheader("EvoluciÃ³n Temporal")
            
            # Timeline de UIR y UIC
            timeline_data = []
            for card in state.cards:
                for i, review in enumerate(card.history):
                    timestamp = review.timestamp if hasattr(review, 'timestamp') else review.get('timestamp', '')
                    if timestamp:
                        timeline_data.append({
                            'timestamp': datetime.fromisoformat(timestamp),
                            'UIR_base': card.UIR_base,  # Valor actual (simplificado)
                            'UIC_local': card.UIC_local
                        })
            
            if timeline_data:
                df_timeline = pd.DataFrame(timeline_data)
                df_timeline = df_timeline.sort_values('timestamp')
                
                # Agrupar por dÃ­a y promediar
                df_timeline['date'] = df_timeline['timestamp'].dt.date
                daily_avg = df_timeline.groupby('date').agg({
                    'UIR_base': 'mean',
                    'UIC_local': 'mean'
                }).reset_index()
                
                fig_timeline = go.Figure()
                fig_timeline.add_trace(go.Scatter(x=daily_avg['date'], y=daily_avg['UIR_base'],
                                                 mode='lines+markers', name='UIR Base Promedio',
                                                 line=dict(color='blue')))
                fig_timeline.add_trace(go.Scatter(x=daily_avg['date'], y=daily_avg['UIC_local']*10,
                                                 mode='lines+markers', name='UIC Local Promedio (Ã—10)',
                                                 line=dict(color='green')))
                
                fig_timeline.update_layout(
                    title="EvoluciÃ³n de UIR y UIC en el Tiempo",
                    xaxis_title="Fecha",
                    yaxis_title="Valor",
                    hovermode='x unified'
                )
                st.plotly_chart(fig_timeline, use_container_width=True)
            else:
                st.info("No hay suficiente historial para mostrar evoluciÃ³n temporal.")
    else:
        st.info("ğŸ‘‹ Â¡Bienvenido! Comienza importando tarjetas en la pÃ¡gina 'Crear/Importar Tarjetas'.")

def page_import():
    """PÃ¡gina para crear e importar tarjetas"""
    st.title("ğŸ“¥ Crear / Importar Tarjetas")
    
    tab1, tab2, tab3 = st.tabs(["âœï¸ Texto", "ğŸ“„ CSV", "ğŸ”— RemNote"])
    
    with tab1:
        st.subheader("Crear tarjetas desde texto")
        st.markdown("Formato: `pregunta == respuesta` (una por lÃ­nea)")
        
        text_input = st.text_area("Ingresa tus tarjetas:", height=200,
                                  placeholder="Â¿QuÃ© es Python? == Un lenguaje de programaciÃ³n\nÂ¿QuÃ© es Streamlit? == Framework para apps de datos")
        
        tags_input = st.text_input("Etiquetas (separadas por comas):", placeholder="python, programaciÃ³n")
    with tab2:
        st.subheader("Importar desde CSV")
        st.markdown("El CSV debe tener columnas: `question,answer` o `front,back` o `item,note`")
        
        uploaded_file = st.file_uploader("Selecciona archivo CSV", type=['csv'])
        
        if uploaded_file:
            try:
                df = pd.read_csv(uploaded_file)
                st.write("Vista previa:", df.head())
                
                # Detectar columnas
                q_col = None
                a_col = None
                
                for col in df.columns:
                    col_lower = col.lower()
                    if col_lower in ['question', 'pregunta', 'front', 'item']:
                        q_col = col
                    if col_lower in ['answer', 'respuesta', 'back', 'note']:
                        a_col = col
                
                if q_col and a_col:
                    st.success(f"âœ… Detectadas columnas: `{q_col}` y `{a_col}`")
                    
                    tags_csv = st.text_input("Etiquetas para todas las tarjetas:", key="csv_tags")
                    
                    if st.button("Importar Tarjetas"):
                        tags = [t.strip() for t in tags_csv.split(',') if t.strip()]
                        created_count = 0
                        
                        for _, row in df.iterrows():
                            question = str(row[q_col]).strip()
                            answer = str(row[a_col]).strip()
                            
                            if question and answer:
                                card = Card(
                                    id=f"card_{len(state.cards)}_{int(time.time())}_{created_count}",
                                    question=question,
                                    answer=answer,
                                    tags=tags
                                )
                                state.cards.append(card)
                                created_count += 1
                        
                        save_state(state)
                        st.success(f"âœ… {created_count} tarjetas importadas!")
                        st.rerun()
                else:
                    st.error("No se encontraron columnas vÃ¡lidas. AsegÃºrate de tener 'question' y 'answer'.")
            except Exception as e:
                st.error(f"Error leyendo CSV: {e}")
    
    
    with tab3:
        st.subheader("Importar desde RemNote (Markdown)")
        st.markdown("RemNote exporta en formato Markdown. Formato: `- Pregunta >>> Respuesta`")
        st.code("""Ejemplo:
- Â¿CuÃ¡les son los propÃ³sitos de la ciencia? >>>
    - Quitar lo superficial y entrar a la esencia
- Â¿QuÃ© es Python? >>> Un lenguaje de programaciÃ³n
        """, language="markdown")
        
        markdown_input = st.text_area("Pega tu export de RemNote (Markdown):", height=300,
                                      placeholder="- Â¿Pregunta 1? >>>\n    - Respuesta 1\n- Â¿Pregunta 2? >>> Respuesta 2")
        
        tags_md = st.text_input("Etiquetas (separadas por comas):", placeholder="remnote, estudio", key="md_tags")
        
        if st.button("Importar desde Markdown"):
            if markdown_input.strip():
                created_count = 0
                errors = []
                tags = [t.strip() for t in tags_md.split(',') if t.strip()]
                
                # Parser para formato RemNote Markdown
                lines = markdown_input.strip().split('\n')
                current_question = None
                current_answer_lines = []
                
                for i, line in enumerate(lines):
                    line_stripped = line.strip()
                    
                    # Detectar pregunta (lÃ­nea que contiene >>>)
                    if '>>>' in line:
                        # Guardar tarjeta anterior si existe
                        if current_question and current_answer_lines:
                            answer = ' '.join(current_answer_lines).strip()
                            if answer:
                                card = Card(
                                    id=f"card_{len(state.cards)}_{int(time.time())}_{created_count}",
                                    question=current_question,
                                    answer=answer,
                                    tags=tags
                                )
                                state.cards.append(card)
                                created_count += 1
                            current_answer_lines = []
                        
                        # Procesar nueva pregunta
                        parts = line.split('>>>', 1)
                        question_part = parts[0].strip()
                        
                        # Limpiar bullets y guiones
                        question_part = question_part.lstrip('-').lstrip('*').strip()
                        current_question = question_part
                        
                        # Si hay respuesta en la misma lÃ­nea
                        if len(parts) > 1 and parts[1].strip():
                            answer_part = parts[1].strip()
                            answer_part = answer_part.lstrip('-').lstrip('*').strip()
                            current_answer_lines.append(answer_part)
                    
                    # LÃ­neas de respuesta (indentadas o con bullets)
                    elif current_question and line_stripped:
                        # Limpiar indentaciÃ³n y bullets
                        answer_line = line_stripped.lstrip('-').lstrip('*').strip()
                        if answer_line:
                            current_answer_lines.append(answer_line)
                    
                    # LÃ­nea vacÃ­a o nueva secciÃ³n sin >>>
                    elif not line_stripped and current_question:
                        # Guardar tarjeta actual
                        if current_answer_lines:
                            answer = ' '.join(current_answer_lines).strip()
                            if answer:
                                card = Card(
                                    id=f"card_{len(state.cards)}_{int(time.time())}_{created_count}",
                                    question=current_question,
                                    answer=answer,
                                    tags=tags
                                )
                                state.cards.append(card)
                                created_count += 1
                        current_question = None
                        current_answer_lines = []
                
                # Guardar Ãºltima tarjeta si existe
                if current_question and current_answer_lines:
                    answer = ' '.join(current_answer_lines).strip()
                    if answer:
                        card = Card(
                            id=f"card_{len(state.cards)}_{int(time.time())}_{created_count}",
                            question=current_question,
                            answer=answer,
                            tags=tags
                        )
                        state.cards.append(card)
                        created_count += 1
                
                if created_count > 0:
                    save_state(state)
                    st.success(f"âœ… {created_count} tarjetas importadas desde RemNote!")
                    
                    # Mostrar preview
                    with st.expander("Ver tarjetas importadas"):
                        for card in state.cards[-created_count:]:
                            st.markdown(f"**Q:** {card.question}")
                            st.markdown(f"**A:** {card.answer}")
                            st.markdown("---")
                    
                    st.rerun()
                else:
                    st.warning("âš ï¸ No se encontraron tarjetas vÃ¡lidas. AsegÃºrate de usar el formato: `- Pregunta >>> Respuesta`")
                    
                if errors:
                    with st.expander("âš ï¸ Errores encontrados"):
                        for error in errors:
                            st.write(error)


def page_review_session():
    """SesiÃ³n interactiva de repaso"""
    st.title("ğŸ¯ SesiÃ³n de Repaso")
    
    session = st.session_state.review_session
    
    if not session['active']:
        # Seleccionar tarjetas para repasar
        st.subheader("Iniciar SesiÃ³n")
        
        if not state.cards:
            st.warning("No hay tarjetas disponibles. Crea algunas primero.")
            return
        
        # Selector de modo de repaso
        st.markdown("### Modo de Repaso")
        review_mode = st.selectbox(
            "Elige cÃ³mo quieres repasar:",
            [
                "Pendientes (por fecha)",
                "Aleatorio",
                "Por tag especÃ­fico",
                "Tarjetas difÃ­ciles (Ã©xito < 50%)",
                "Solo tarjetas nuevas",
                "Repaso espaciado Ã³ptimo (por UIR)"
            ]
        )
        
        # Filtrar tarjetas segÃºn el modo
        today = datetime.now()
        cards_to_review_indices = []
        
        if review_mode == "Pendientes (por fecha)":
            cards_to_review_indices = [i for i, c in enumerate(state.cards)
                                      if not c.next_review or datetime.fromisoformat(c.next_review) <= today]
        
        elif review_mode == "Aleatorio":
            cards_to_review_indices = list(range(len(state.cards)))
            import random
            random.shuffle(cards_to_review_indices)
        
        elif review_mode == "Por tag especÃ­fico":
            # Obtener todos los tags Ãºnicos
            all_tags = set()
            for card in state.cards:
                all_tags.update(card.tags)
            
            if all_tags:
                selected_tag = st.selectbox("Selecciona tag:", sorted(all_tags))
                cards_to_review_indices = [i for i, c in enumerate(state.cards)
                                          if selected_tag in c.tags]
            else:
                st.warning("No hay tags disponibles.")
                return
        
        elif review_mode == "Tarjetas difÃ­ciles (Ã©xito < 50%)":
            for i, card in enumerate(state.cards):
                if card.history:
                    # Calcular tasa de Ã©xito
                    recent = card.history[-5:]
                    successes = sum(1 for r in recent 
                                  if (r.grade if hasattr(r, 'grade') else r.get('grade', 0)) >= 2)
                    success_rate = successes / len(recent)
                    if success_rate < 0.5:
                        cards_to_review_indices.append(i)
        
        elif review_mode == "Solo tarjetas nuevas":
            cards_to_review_indices = [i for i, c in enumerate(state.cards)
                                      if c.review_count == 0]
        
        elif review_mode == "Repaso espaciado Ã³ptimo (por UIR)":
            # Ordenar por UIR efectivo (menor primero = mÃ¡s urgente)
            card_uir_pairs = [(i, c.UIR_effective) for i, c in enumerate(state.cards)]
            card_uir_pairs.sort(key=lambda x: x[1])
            cards_to_review_indices = [i for i, _ in card_uir_pairs]
        
        # Mostrar informaciÃ³n
        st.write(f"**Tarjetas en este modo:** {len(cards_to_review_indices)}")
        st.write(f"**Total tarjetas:** {len(state.cards)}")
        
        # Botones de inicio
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸš€ Iniciar SesiÃ³n", type="primary", disabled=len(cards_to_review_indices)==0):
                session['active'] = True
                session['cards_to_review'] = cards_to_review_indices
                session['current_card_idx'] = 0
                session['show_answer'] = False
                session['start_time'] = time.time()
                st.rerun()
        
        with col2:
            if st.button("ğŸ“‹ Repasar Todas"):
                session['active'] = True
                session['cards_to_review'] = list(range(len(state.cards)))
                session['current_card_idx'] = 0
                session['show_answer'] = False
                session['start_time'] = time.time()
                st.rerun()
    
    else:
        # SesiÃ³n activa
        cards_to_review = session['cards_to_review']
        current_idx = session['current_card_idx']
        
        if current_idx >= len(cards_to_review):
            st.success("ğŸ‰ Â¡SesiÃ³n completada!")
            st.balloons()
            
            if st.button("Volver al Dashboard"):
                session['active'] = False
                st.session_state.current_page = "Dashboard"
                st.rerun()
            return
        
        card_idx = cards_to_review[current_idx]
        card = state.cards[card_idx]
        
        # Mostrar progreso
        st.progress((current_idx + 1) / len(cards_to_review))
        st.caption(f"Tarjeta {current_idx + 1} de {len(cards_to_review)}")
        
        # Mostrar pregunta
        st.markdown(f"### {card.question}")
        
        if not session['show_answer']:
            if st.button("ğŸ‘ï¸ Mostrar Respuesta", type="primary"):
                session['show_answer'] = True
                session['show_time'] = time.time()
                st.rerun()
        else:
            # Mostrar respuesta
            st.markdown(f"**Respuesta:** {card.answer}")
            
            st.markdown("---")
            st.subheader("Â¿CÃ³mo fue tu respuesta?")
            
            # Predecir intervalos para todas las opciones
            predictions = predict_intervals_for_all_grades(card, state.params)
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.button("âŒ Again", use_container_width=True, key="btn_again",
                         on_click=process_review, args=(card, 0, session))
                st.caption(f"ğŸ”µ Anki+UIR: **{predictions['anki_uir'][0]}d**")
                st.caption(f"âšª Anki: {predictions['anki_classic'][0]}d")
            with col2:
                st.button("ğŸ˜“ Hard", use_container_width=True, key="btn_hard",
                         on_click=process_review, args=(card, 1, session))
                st.caption(f"ğŸ”µ Anki+UIR: **{predictions['anki_uir'][1]}d**")
                st.caption(f"âšª Anki: {predictions['anki_classic'][1]}d")
            with col3:
                st.button("âœ… Good", use_container_width=True, key="btn_good",
                         on_click=process_review, args=(card, 2, session))
                st.caption(f"ğŸ”µ Anki+UIR: **{predictions['anki_uir'][2]}d**")
                st.caption(f"âšª Anki: {predictions['anki_classic'][2]}d")
            with col4:
                st.button("ğŸŒŸ Easy", use_container_width=True, key="btn_easy",
                         on_click=process_review, args=(card, 3, session))
                st.caption(f"ğŸ”µ Anki+UIR: **{predictions['anki_uir'][3]}d**")
                st.caption(f"âšª Anki: {predictions['anki_classic'][3]}d")
            
            # Mostrar info de la tarjeta
            st.markdown("---")
            col_a, col_b, col_c = st.columns(3)
            with col_a:
                st.metric("UIC Local", f"{card.UIC_local:.3f}")
            with col_b:
    session['current_card_idx'] += 1
    session['show_answer'] = False
    session['start_time'] = time.time()

def page_analytics():
    """PÃ¡gina de Analytics avanzado con comparaciÃ³n temporal"""
    st.title("ğŸ“Š Analytics Avanzado")
    
    if not state.cards:
        st.warning("No hay tarjetas para analizar.")
        return
    
    # Selector de perÃ­odo para comparaciÃ³n temporal
    st.sidebar.markdown("### ğŸ• ComparaciÃ³n Temporal")
    period = st.sidebar.selectbox("PerÃ­odo", ["Ãšltima semana", "Ãšltimo mes", "Ãšltimos 3 meses"])
    
    # Calcular fechas
    today = datetime.now()
    if period == "Ãšltima semana":
        days_back = 7
    elif period == "Ãšltimo mes":
        days_back = 30
    else:
        days_back = 90
    
    cutoff_date = today - timedelta(days=days_back)
    
    # Tabs para organizar analytics
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“ˆ MÃ©tricas", "ğŸ¯ RetenciÃ³n por Tag", "âš ï¸ ProblemÃ¡ticas", "ğŸ“… PredicciÃ³n"])
    
    with tab1:
        st.subheader("MÃ©tricas Generales")
        
        # MÃ©tricas actuales
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            avg_uir_current = np.mean([c.UIR_effective for c in state.cards])
            st.metric("UIR Promedio", f"{avg_uir_current:.1f}d")
        
        with col2:
            avg_uic_current = np.mean([c.UIC_local for c in state.cards])
            st.metric("UIC Promedio", f"{avg_uic_current:.3f}")
        
        with col3:
            # Tasa de Ã©xito global
            all_grades = []
            for c in state.cards:
                for r in c.history:
                    grade = r.grade if hasattr(r, 'grade') else r.get('grade', 0)
                    all_grades.append(grade)
            
            if all_grades:
                success_rate = sum(1 for g in all_grades if g >= 2) / len(all_grades)
                st.metric("Tasa de Ã‰xito", f"{success_rate*100:.1f}%")
            else:
                st.metric("Tasa de Ã‰xito", "N/A")
        
        with col4:
            # Repasos totales
            total_reviews = sum(len(c.history) for c in state.cards)
            st.metric("Repasos Totales", total_reviews)
        
        # ComparaciÃ³n temporal (deltas)
        st.markdown("---")
        st.subheader(f"Cambios en {period}")
        
        # Calcular mÃ©tricas del perÃ­odo anterior
        old_reviews = []
        recent_reviews = []
        
        for card in state.cards:
            for review in card.history:
                timestamp = review.timestamp if hasattr(review, 'timestamp') else review.get('timestamp', '')
                if timestamp:
                    review_date = datetime.fromisoformat(timestamp)
                    if review_date >= cutoff_date:
                        recent_reviews.append(review)
                    else:
                        old_reviews.append(review)
        
        col_a, col_b, col_c = st.columns(3)
        
        with col_a:
            # Delta en repasos
            delta_reviews = len(recent_reviews)
            st.metric("Repasos en PerÃ­odo", delta_reviews)
        
        with col_b:
            # Delta en tasa de Ã©xito
            if recent_reviews:
                recent_success = sum(1 for r in recent_reviews 
                                   if (r.grade if hasattr(r, 'grade') else r.get('grade', 0)) >= 2) / len(recent_reviews)
                st.metric("Ã‰xito Reciente", f"{recent_success*100:.1f}%")
            else:
                st.metric("Ã‰xito Reciente", "N/A")
        
        with col_c:
            # Promedio de repasos por dÃ­a
            if recent_reviews:
                avg_per_day = len(recent_reviews) / days_back
                st.metric("Repasos/DÃ­a", f"{avg_per_day:.1f}")
            else:
                st.metric("Repasos/DÃ­a", "0")
        
        # GrÃ¡fica de tendencia
        if recent_reviews:
            df_recent = pd.DataFrame([{
                'date': datetime.fromisoformat(r.timestamp if hasattr(r, 'timestamp') else r.get('timestamp', '')).date(),
                'grade': r.grade if hasattr(r, 'grade') else r.get('grade', 0)
            } for r in recent_reviews if hasattr(r, 'timestamp') or 'timestamp' in r])
            
            daily_stats = df_recent.groupby('date').agg({
                'grade': ['count', 'mean']
            }).reset_index()
            daily_stats.columns = ['date', 'count', 'avg_grade']
            
            fig_trend = go.Figure()
            fig_trend.add_trace(go.Scatter(x=daily_stats['date'], y=daily_stats['count'],
                                          mode='lines+markers', name='Repasos por DÃ­a'))
            fig_trend.update_layout(title=f"Tendencia de Actividad ({period})",
                                   xaxis_title="Fecha", yaxis_title="Repasos")
            st.plotly_chart(fig_trend, use_container_width=True)
    
    with tab2:
        st.subheader("RetenciÃ³n por Tag")
        
        # Agrupar por tags
        tag_stats = {}
        for card in state.cards:
            for tag in card.tags:
                if tag not in tag_stats:
                    tag_stats[tag] = {'cards': 0, 'reviews': 0, 'successes': 0}
                
                tag_stats[tag]['cards'] += 1
    
    # Si es "Again" (grade=0), volver a agregar la tarjeta al final de la cola
    if grade == 0:
        current_card_idx = session["cards_to_review"][session["current_card_idx"]]
        session["cards_to_review"].append(current_card_idx)
                tag_stats[tag]['reviews'] += len(card.history)
                
                for r in card.history:
                    grade = r.grade if hasattr(r, 'grade') else r.get('grade', 0)
                    if grade >= 2:
                        tag_stats[tag]['successes'] += 1
        
        if tag_stats:
            # Calcular tasa de Ã©xito por tag
            tag_data = []
            for tag, stats in tag_stats.items():
                success_rate = (stats['successes'] / stats['reviews'] * 100) if stats['reviews'] > 0 else 0
                tag_data.append({
                    'Tag': tag,
                    'Tarjetas': stats['cards'],
                    'Repasos': stats['reviews'],
                    'Tasa de Ã‰xito (%)': success_rate
                })
            
            df_tags = pd.DataFrame(tag_data).sort_values('Tasa de Ã‰xito (%)', ascending=False)
            st.dataframe(df_tags, use_container_width=True)
            
            # GrÃ¡fica de barras
            fig_tags = px.bar(df_tags, x='Tag', y='Tasa de Ã‰xito (%)',
                             title="Tasa de Ã‰xito por Tag",
                             color='Tasa de Ã‰xito (%)',
                             color_continuous_scale='RdYlGn')
            st.plotly_chart(fig_tags, use_container_width=True)
        else:
            st.info("No hay tags para analizar.")
    
    with tab3:
        st.subheader("Tarjetas ProblemÃ¡ticas")
        
        # Identificar tarjetas con baja tasa de Ã©xito
        problematic = []
        for card in state.cards:
            if len(card.history) >= 3:  # Al menos 3 repasos
                recent = card.history[-5:]
                successes = sum(1 for r in recent 
                              if (r.grade if hasattr(r, 'grade') else r.get('grade', 0)) >= 2)
                success_rate = successes / len(recent)
                
                if success_rate < 0.5:  # Menos de 50% de Ã©xito
                    problematic.append({
                        'Pregunta': card.question[:60],
                        'Repasos': len(card.history),
                        'Ã‰xito (%)': success_rate * 100,
                        'UIR': card.UIR_effective,
                        'UIC': card.UIC_local
                    })
        
        if problematic:
            df_prob = pd.DataFrame(problematic).sort_values('Ã‰xito (%)')
            st.dataframe(df_prob, use_container_width=True)
            
            st.markdown("### ğŸ’¡ Recomendaciones")
            st.info(f"**{len(problematic)} tarjetas** necesitan atenciÃ³n. Considera:\n"
                   "- Revisar si la pregunta/respuesta es clara\n"
                   "- Dividir en tarjetas mÃ¡s simples\n"
                   "- Agregar contexto o ejemplos\n"
                   "- Conectar con otras tarjetas (mejorar UIC)")
        else:
            st.success("âœ… No hay tarjetas problemÃ¡ticas. Â¡Buen trabajo!")
    
    with tab4:
        st.subheader("PredicciÃ³n de Carga de Trabajo")
        
        # Predecir repasos en prÃ³ximos dÃ­as
        prediction_days = st.slider("DÃ­as a predecir", 7, 90, 30)
        
        workload = {i: 0 for i in range(prediction_days)}
        
        for card in state.cards:
            if card.next_review:
                try:
                    next_dt = datetime.fromisoformat(card.next_review)
                    days_until = (next_dt - today).days
                    
                    if 0 <= days_until < prediction_days:
                        workload[days_until] += 1
                except:
                    pass
        
        df_workload = pd.DataFrame({
            'DÃ­a': list(workload.keys()),
            'Repasos Esperados': list(workload.values())
        })
        
        fig_workload = px.bar(df_workload, x='DÃ­a', y='Repasos Esperados',
                             title=f"Carga de Trabajo Proyectada ({prediction_days} dÃ­as)",
                             labels={'DÃ­a': 'DÃ­as desde hoy'})
        st.plotly_chart(fig_workload, use_container_width=True)
        
        # EstadÃ­sticas de la predicciÃ³n
        col_x, col_y, col_z = st.columns(3)
        with col_x:
            st.metric("Total Proyectado", sum(workload.values()))
        with col_y:
            st.metric("Promedio/DÃ­a", f"{sum(workload.values())/prediction_days:.1f}")
        with col_z:
            max_day = max(workload, key=workload.get)
            st.metric("DÃ­a Pico", f"DÃ­a {max_day} ({workload[max_day]} repasos)")

def page_semantic_graph():
    """VisualizaciÃ³n del grafo semÃ¡ntico"""
    st.title("ğŸ•¸ï¸ Grafo SemÃ¡ntico")
    
    if len(state.cards) < 2:
        st.warning("Necesitas al menos 2 tarjetas para construir el grafo.")
        return
    
    if st.button("ğŸ”„ Reconstruir Grafo", type="primary"):
        with st.spinner("Calculando TF-IDF y similitudes..."):
            tfidf_matrix, vectorizer = compute_tfidf_from_cards(state.cards)
            if tfidf_matrix is not None:
                state.tfidf_matrix = tfidf_matrix
                state.similarity_matrix = compute_similarity_matrix(tfidf_matrix)
    
    # Heatmap
    st.subheader("Mapa de Calor de Similitudes")
    
    fig = px.imshow(state.similarity_matrix,
                    labels=dict(x="Tarjeta", y="Tarjeta", color="Similitud"),
                    x=[f"C{i}" for i in range(len(state.cards))],
                    y=[f"C{i}" for i in range(len(state.cards))],
                    color_continuous_scale="Viridis")
    st.plotly_chart(fig, use_container_width=True)
    
    # Tabla de similitudes
    st.subheader("Pares MÃ¡s Similares")
    
    pairs = []
    n = len(state.cards)
    for i in range(n):
        for j in range(i+1, n):
            pairs.append({
                'Tarjeta 1': state.cards[i].question[:50],
                'Tarjeta 2': state.cards[j].question[:50],
                'Similitud': state.similarity_matrix[i, j]
            })
    
    df_pairs = pd.DataFrame(pairs).sort_values('Similitud', ascending=False).head(10)
    st.dataframe(df_pairs, use_container_width=True)
    
    # Grafo interactivo
    st.subheader("Grafo Interactivo")
    
    threshold = st.slider("Umbral de similitud", 0.0, 1.0, 0.3, 0.05)
    
    # Crear grafo con NetworkX
    G = nx.Graph()
    
    for i, card in enumerate(state.cards):
        G.add_node(i, label=card.question[:30], title=card.question,
                  size=10 + card.UIC_local * 20)
    
    for i in range(n):
        for j in range(i+1, n):
            if state.similarity_matrix[i, j] > threshold:
                G.add_edge(i, j, weight=state.similarity_matrix[i, j])
    
    # Visualizar con pyvis
    net = Network(height="600px", width="100%", bgcolor="#222222", font_color="white")
    net.from_nx(G)
    net.save_graph("data/graph.html")
    
    with open("data/graph.html", 'r', encoding='utf-8') as f:
        html_content = f.read()
    
    st.components.v1.html(html_content, height=600)

def page_algorithm_comparison():
    """ComparaciÃ³n de algoritmos de scheduling"""
    st.title("âš–ï¸ Comparador de Algoritmos")
    
    if not state.cards:
        st.warning("No hay tarjetas para comparar.")
        return
    
    st.subheader("ParÃ¡metros del Modelo")
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        alpha = st.number_input("Alpha (Î±)", 0.0, 1.0, state.params['alpha'], 0.05)
    with col2:
        gamma = st.number_input("Gamma (Î³)", 0.0, 1.0, state.params['gamma'], 0.05)
    with col3:
        delta = st.number_input("Delta (Î´)", 0.0, 1.0, state.params['delta'], 0.01)
    with col4:
        eta = st.number_input("Eta (Î·)", 0.0, 1.0, state.params['eta'], 0.01)
    
    if st.button("Actualizar ParÃ¡metros"):
        state.params.update({'alpha': alpha, 'gamma': gamma, 'delta': delta, 'eta': eta})
        save_state(state)
        st.success("ParÃ¡metros actualizados!")
    
    st.markdown("---")
    st.subheader("ComparaciÃ³n de Intervalos")
    
    # Tabla comparativa
    comparison_data = []
    
    for card in state.cards[:20]:  # Limitar a 20 para no saturar
        # Simular prÃ³ximo intervalo para cada algoritmo
        # (sin modificar la tarjeta real)
        card_copy = Card(**asdict(card))
        
        # Anki clÃ¡sico
        i_classic = anki_classic_schedule(card_copy, 2)  # Asumiendo "Good"
        
        # Anki+UIR
        card_copy2 = Card(**asdict(card))
        i_uir = anki_uir_adapted_schedule(card_copy2, 2, state.params)
        
        comparison_data.append({
            'Pregunta': card.question[:40],
            'Anki ClÃ¡sico (dÃ­as)': i_classic,
            'Anki+UIR (dÃ­as)': i_uir,
            'Diferencia (%)': ((i_uir - i_classic) / i_classic * 100) if i_classic > 0 else 0,
            'UIC Local': f"{card.UIC_local:.3f}",
            'UIR Efectivo': f"{card.UIR_effective:.1f}"
        })
    
    df_comp = pd.DataFrame(comparison_data)
    st.dataframe(df_comp, use_container_width=True)
    
    # GrÃ¡fica de distribuciÃ³n de intervalos
    fig = go.Figure()
    fig.add_trace(go.Histogram(x=df_comp['Anki ClÃ¡sico (dÃ­as)'], name='Anki ClÃ¡sico', opacity=0.7))
    fig.add_trace(go.Histogram(x=df_comp['Anki+UIR (dÃ­as)'], name='Anki+UIR', opacity=0.7))
    fig.update_layout(title="DistribuciÃ³n de Intervalos Recomendados",
                     xaxis_title="DÃ­as", yaxis_title="Frecuencia", barmode='overlay')
    st.plotly_chart(fig, use_container_width=True)

def page_simulation():
    """SimulaciÃ³n de sesiones de repaso"""
    st.title("ğŸ”¬ SimulaciÃ³n")
    
    st.subheader("ConfiguraciÃ³n de SimulaciÃ³n")
    
    col1, col2 = st.columns(2)
    with col1:
        horizon = st.number_input("Horizonte (dÃ­as)", 1, 365, 180)
    with col2:
        algorithm = st.selectbox("Algoritmo", ["Anki ClÃ¡sico", "Anki+UIR"])
    
    if st.button("â–¶ï¸ Ejecutar SimulaciÃ³n"):
        if not state.cards:
            st.warning("No hay tarjetas para simular.")
            return
        
        with st.spinner("Simulando..."):
            # SimulaciÃ³n simple: contar repasos por dÃ­a
            daily_reviews = {i: 0 for i in range(horizon)}
            
            for card in state.cards:
                card_copy = Card(**asdict(card))
                current_day = 0
                
                while current_day < horizon:
                    # Simular repaso con probabilidad
                    grade = np.random.choice([0, 1, 2, 3], p=[0.05, 0.15, 0.5, 0.3])
                    
                    if algorithm == "Anki ClÃ¡sico":
                        interval = anki_classic_schedule(card_copy, grade)
                    else:
                        interval = anki_uir_adapted_schedule(card_copy, grade, state.params)
                    
                    daily_reviews[current_day] += 1
                    current_day += interval
            
            # Visualizar
            df_sim = pd.DataFrame({
                'DÃ­a': list(daily_reviews.keys()),
                'Repasos': list(daily_reviews.values())
            })
            
            fig = px.line(df_sim, x='DÃ­a', y='Repasos', 
                         title=f"Repasos por DÃ­a - {algorithm}")
            st.plotly_chart(fig, use_container_width=True)
            
            st.metric("Total de Repasos", sum(daily_reviews.values()))

def page_calibration():
    """CalibraciÃ³n de parÃ¡metros"""
    st.title("ğŸ›ï¸ CalibraciÃ³n de ParÃ¡metros")
    
    st.subheader("ParÃ¡metros Actuales")
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Alpha (Î±)", f"{state.params['alpha']:.3f}")
    with col2:
        st.metric("Gamma (Î³)", f"{state.params['gamma']:.3f}")
    with col3:
        st.metric("Delta (Î´)", f"{state.params['delta']:.3f}")
    with col4:
        st.metric("Eta (Î·)", f"{state.params['eta']:.3f}")
    
    st.markdown("---")
    
    # Recopilar historial de repasos
    all_reviews = []
    for card in state.cards:
        all_reviews.extend(card.history)
    
    st.write(f"**Total de repasos registrados:** {len(all_reviews)}")
    
    if len(all_reviews) < 10:
        st.warning("Necesitas al menos 10 repasos para calibrar los parÃ¡metros.")
        return
    
    if st.button("ğŸ”§ Calibrar ParÃ¡metros"):
        with st.spinner("Optimizando parÃ¡metros..."):
            # CalibraciÃ³n simple usando grid search
            best_params = state.params.copy()
            # En una implementaciÃ³n real, usarÃ­amos scipy.optimize
            st.info("CalibraciÃ³n completada (placeholder - implementar optimizaciÃ³n real)")
            
    st.markdown("---")
    st.subheader("Historial de Repasos")
    
    if all_reviews:
        df_history = pd.DataFrame([{
            'Timestamp': r.timestamp,
            'Grade': r.grade,
            'Response Time': f"{r.response_time:.1f}s",
            'P_recall': f"{r.P_recall:.2f}"
        } for r in all_reviews[-20:]])  # Ãšltimos 20
        
        st.dataframe(df_history, use_container_width=True)

def page_export_import():
    """Export e import de datos"""
    st.title("ğŸ’¾ Export / Import")
    
    tab1, tab2 = st.tabs(["ğŸ“¤ Export", "ğŸ“¥ Import"])
    
    with tab1:
        st.subheader("Exportar Datos")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("Exportar Tarjetas (CSV)", use_container_width=True):
                if state.cards:
                    df_export = pd.DataFrame([{
                        'question': c.question,
                        'answer': c.answer,
                        'tags': ','.join(c.tags),
                        'review_count': c.review_count,
                        'UIC_local': c.UIC_local,
                        'UIR_effective': c.UIR_effective
                    } for c in state.cards])
                    
                    csv = df_export.to_csv(index=False)
                    st.download_button("â¬‡ï¸ Descargar CSV", csv, "cards_export.csv", "text/csv")
                else:
                    st.warning("No hay tarjetas para exportar.")
        
        with col2:
            if st.button("Exportar Estado Completo (JSON)", use_container_width=True):
                state_dict = {
                    'cards': [asdict(card) for card in state.cards],
                    'params': state.params,
                    'last_updated': datetime.now().isoformat()
                }
                
                json_str = json.dumps(state_dict, indent=2, ensure_ascii=False)
                st.download_button("â¬‡ï¸ Descargar JSON", json_str, "state_export.json", "application/json")
    
    with tab2:
        st.subheader("Importar Estado")
        
        uploaded_json = st.file_uploader("Selecciona archivo JSON de estado", type=['json'])
        
        if uploaded_json:
            if st.button("âš ï¸ Importar y Reemplazar Estado Actual"):
                try:
                    state_dict = json.load(uploaded_json)
                    
                    # Reconstruir estado
                    cards = [Card(**card_data) for card_data in state_dict.get('cards', [])]
                    for card in cards:
                        card.history = [ReviewHistory(**h) if isinstance(h, dict) else h 
                                       for h in card.history]
                    
                    state.cards = cards
                    state.params = state_dict.get('params', state.params)
                    
                    save_state(state)
                    st.success("âœ… Estado importado exitosamente!")
                    st.rerun()
                except Exception as e:
                    st.error(f"Error importando estado: {e}")

# ============================================================================
# MAIN APP ROUTING
# ============================================================================

current_page = st.session_state.current_page

if current_page == "Dashboard":
    page_dashboard()
elif current_page == "Crear/Importar Tarjetas":
    page_import()
elif current_page == "SesiÃ³n de Repaso":
    page_review_session()
elif current_page == "ğŸ“Š Analytics":
    page_analytics()
elif current_page == "Grafo SemÃ¡ntico":
    page_semantic_graph()
elif current_page == "Comparador de Algoritmos":
    page_algorithm_comparison()
elif current_page == "SimulaciÃ³n":
    page_simulation()
elif current_page == "CalibraciÃ³n":
    page_calibration()
elif current_page == "Export/Import":
    page_export_import()

